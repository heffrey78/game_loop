"""
Integration tests for memory integration with ConversationFlowManager.

These tests validate the complete memory integration pipeline using actual
SemanticMemoryRepository and database operations.
"""

import uuid
from datetime import datetime, timedelta
from unittest.mock import AsyncMock, Mock

import pytest
from sqlalchemy.ext.asyncio import AsyncSession

from game_loop.core.conversation.conversation_models import (
    ConversationContext,
    ConversationExchange,
    MessageType,
    NPCPersonality,
)
from game_loop.core.conversation.flow_manager import ConversationFlowManager
from game_loop.core.conversation.memory_integration import (
    MemoryContext,
    MemoryIntegrationInterface,
    MemoryRetrievalResult,
    MemoryDisclosureLevel,
    ConversationFlowState,
)
from game_loop.database.models.semantic_memory import SemanticMemoryEntry
from game_loop.database.repositories.conversation import ConversationRepositoryManager
from game_loop.database.repositories.semantic_memory import SemanticMemoryRepository
from game_loop.database.session_factory import DatabaseSessionFactory
from game_loop.llm.ollama.client import OllamaClient


@pytest.fixture
async def semantic_memory_repo(db_session: AsyncSession) -> SemanticMemoryRepository:
    """Create semantic memory repository for testing."""
    return SemanticMemoryRepository(db_session)


@pytest.fixture
async def mock_ollama_client() -> OllamaClient:
    """Create mock Ollama client for LLM operations."""
    mock_client = AsyncMock(spec=OllamaClient)

    # Configure realistic responses
    mock_client.generate_response.return_value = "village_history"

    # Mock embedding generation (would normally return actual embeddings)
    mock_client.generate_embeddings = AsyncMock(
        return_value=[0.1] * 384
    )  # Typical embedding size

    return mock_client


@pytest.fixture
async def real_memory_integration(
    session_factory: DatabaseSessionFactory,
    mock_ollama_client: OllamaClient,
) -> MemoryIntegrationInterface:
    """Create real memory integration interface with database backing."""
    return MemoryIntegrationInterface(
        session_factory=session_factory,
        llm_client=mock_ollama_client,
        enable_memory_enhancement=True,
        similarity_threshold=0.6,
        max_memories_per_query=5,
    )


@pytest.fixture
async def conversation_with_semantic_memories(
    db_session: AsyncSession,
    semantic_memory_repo: SemanticMemoryRepository,
) -> tuple[ConversationContext, list[SemanticMemoryEntry]]:
    """Create conversation context with pre-populated semantic memories."""
    conversation_id = uuid.uuid4()
    player_id = uuid.uuid4()
    npc_id = uuid.uuid4()

    # Create conversation context
    conversation = ConversationContext(
        conversation_id=conversation_id,
        player_id=player_id,
        npc_id=npc_id,
        topic="village_history",
        mood="curious",
        relationship_level=0.4,
        status="active",
    )

    # Create semantic memory entries related to village history
    memories = []
    memory_contents = [
        "The old temple was built three centuries ago by the first settlers.",
        "There's a legend about treasure hidden beneath the village well.",
        "The annual harvest festival celebrates our agricultural traditions.",
        "Elder Marcus knows the most about our village's founding stories.",
        "The mysterious stones near the forest edge have ancient markings.",
    ]

    for i, content in enumerate(memory_contents):
        # Create realistic embedding (normally would be generated by actual LLM)
        embedding = [0.1 + (i * 0.1)] * 384  # Simple pattern for testing

        memory = SemanticMemoryEntry(
            conversation_id=conversation_id,
            npc_id=npc_id,
            player_id=player_id,
            memory_text=content,
            embedding=embedding,
            importance_score=0.7 + (i * 0.05),
            emotional_weight=0.5,
            created_at=datetime.utcnow() - timedelta(days=i),
        )

        memories.append(await semantic_memory_repo.create_memory_entry(memory))

    return conversation, memories


@pytest.mark.asyncio
class TestMemoryIntegrationWithSemanticRepository:
    """Test memory integration using real SemanticMemoryRepository."""

    async def test_extract_memory_context_with_real_llm_calls(
        self,
        real_memory_integration: MemoryIntegrationInterface,
        conversation_with_semantic_memories: tuple[
            ConversationContext, list[SemanticMemoryEntry]
        ],
    ):
        """Test memory context extraction with actual LLM integration."""
        conversation, _ = conversation_with_semantic_memories

        # Create realistic NPC personality
        npc_personality = NPCPersonality(
            npc_id=uuid.UUID(conversation.npc_id),
            traits={"wise": 0.8, "talkative": 0.7},
            knowledge_areas=["history", "local_lore", "traditions"],
            speech_patterns={"formality": "medium"},
            background_story="Village elder with deep historical knowledge.",
            default_mood="contemplative",
            relationships={},
        )

        # Test context extraction
        memory_context = await real_memory_integration.extract_memory_context(
            conversation=conversation,
            player_message="Tell me about the old temple in your village.",
            npc_personality=npc_personality,
        )

        # Verify extracted context
        assert memory_context.current_topic is not None
        assert memory_context.emotional_tone is not None
        assert len(memory_context.npc_knowledge_areas) == 3
        assert "history" in memory_context.npc_knowledge_areas
        assert (
            memory_context.session_disclosure_level == MemoryDisclosureLevel.NONE
        )  # Initial state

    async def test_retrieve_memories_with_semantic_search(
        self,
        real_memory_integration: MemoryIntegrationInterface,
        conversation_with_semantic_memories: tuple[
            ConversationContext, list[SemanticMemoryEntry]
        ],
    ):
        """Test memory retrieval using semantic search on actual database."""
        conversation, stored_memories = conversation_with_semantic_memories
        npc_id = uuid.UUID(conversation.npc_id)

        # Create memory context for temple query
        memory_context = MemoryContext(
            current_topic="temple_history",
            emotional_tone="curious",
            npc_knowledge_areas=["history", "local_lore"],
            session_disclosure_level=MemoryDisclosureLevel.SUBTLE_HINTS,
        )

        # Generate query embedding for temple-related content
        query_embedding = [0.1] * 384  # Should match our first memory entry

        # Retrieve relevant memories
        memory_result = await real_memory_integration.retrieve_relevant_memories(
            memory_context=memory_context,
            npc_id=npc_id,
            query_embedding=query_embedding,
        )

        # Verify retrieval results
        assert not memory_result.fallback_triggered
        assert memory_result.error_message is None
        assert len(memory_result.relevant_memories) > 0

        # Check that relevant memories contain expected content
        memory_texts = [
            memory.memory_text for memory, _ in memory_result.relevant_memories
        ]
        assert any("temple" in text.lower() for text in memory_texts)

        # Verify scoring and recommendations
        assert memory_result.context_score > 0
        assert memory_result.disclosure_recommendation in MemoryDisclosureLevel

    async def test_memory_integration_flow_analysis(
        self,
        real_memory_integration: MemoryIntegrationInterface,
        conversation_with_semantic_memories: tuple[
            ConversationContext, list[SemanticMemoryEntry]
        ],
    ):
        """Test conversation flow analysis with actual memory data."""
        conversation, _ = conversation_with_semantic_memories
        npc_id = uuid.UUID(conversation.npc_id)

        # Test different emotional contexts
        test_cases = [
            ("curious", MemoryDisclosureLevel.SUBTLE_HINTS),
            ("excited", MemoryDisclosureLevel.CLEAR_REFERENCES),
            ("worried", MemoryDisclosureLevel.NONE),
        ]

        for emotional_tone, expected_min_disclosure in test_cases:
            memory_context = MemoryContext(
                current_topic="village_secrets",
                emotional_tone=emotional_tone,
                npc_knowledge_areas=["history", "secrets"],
                session_disclosure_level=MemoryDisclosureLevel.SUBTLE_HINTS,
                topic_continuity_score=0.8,
            )

            memory_result = await real_memory_integration.retrieve_relevant_memories(
                memory_context=memory_context,
                npc_id=npc_id,
            )

            # Verify flow analysis considers emotional alignment
            assert isinstance(memory_result.flow_analysis, ConversationFlowState)

            # Emotional tone should influence disclosure recommendations
            if emotional_tone == "worried":
                # Worried tone should be more conservative
                assert memory_result.disclosure_recommendation in [
                    MemoryDisclosureLevel.NONE,
                    MemoryDisclosureLevel.SUBTLE_HINTS,
                ]


@pytest.mark.asyncio
class TestEndToEndMemoryFlowIntegration:
    """Test complete memory integration flow with ConversationFlowManager."""

    async def test_complete_memory_enhanced_response_flow(
        self,
        session_factory: DatabaseSessionFactory,
        real_memory_integration: MemoryIntegrationInterface,
        conversation_with_semantic_memories: tuple[
            ConversationContext, list[SemanticMemoryEntry]
        ],
    ):
        """Test complete flow from player message to memory-enhanced NPC response."""
        conversation, stored_memories = conversation_with_semantic_memories

        # Create NPC personality with memory-relevant traits
        npc_personality = NPCPersonality(
            npc_id=uuid.UUID(conversation.npc_id),
            traits={"wise": 0.9, "secretive": 0.3, "helpful": 0.8},
            knowledge_areas=["history", "local_lore", "traditions"],
            speech_patterns={"formality": "high", "verbosity": "medium"},
            background_story="Ancient keeper of village knowledge and traditions.",
            default_mood="contemplative",
            relationships={},
        )

        # Create flow manager with real memory integration
        flow_manager = ConversationFlowManager(
            memory_integration=real_memory_integration,
            session_factory=session_factory,
        )

        # Test memory-enhanced response
        base_response = "Our village has a long and storied past."
        player_message = (
            "I'm fascinated by the old temple. What can you tell me about it?"
        )

        enhanced_response, integration_data = (
            await flow_manager.enhance_response_with_memory_patterns(
                conversation=conversation,
                personality=npc_personality,
                base_response=base_response,
                player_message=player_message,
                npc_id=npc_personality.npc_id,
            )
        )

        # Verify memory enhancement occurred
        assert integration_data.get("memory_enhanced", False)
        assert len(enhanced_response) >= len(base_response)

        # Verify integration metadata
        assert "confidence" in integration_data
        assert "pattern_used" in integration_data
        assert "disclosure_level" in integration_data

        # Enhanced response should reference temple-related memories
        assert len(enhanced_response) > len(base_response)

    async def test_memory_integration_with_conversation_progression(
        self,
        session_factory: DatabaseSessionFactory,
        real_memory_integration: MemoryIntegrationInterface,
        conversation_repo_manager: ConversationRepositoryManager,
    ):
        """Test memory integration as conversation relationship progresses."""
        # Create NPC with memory-rich personality
        npc_id = uuid.uuid4()
        npc_personality = await conversation_repo_manager.npc_personalities.create_personality(
            npc_id=npc_id,
            traits={"wise": 0.9, "cautious": 0.7, "observant": 0.8},
            knowledge_areas=["ancient_history", "village_secrets", "magic_lore"],
            speech_patterns={"formality": "high", "metaphorical": True},
            background_story="Ancient sage who has witnessed centuries of village history.",
        )

        # Create flow manager
        flow_manager = ConversationFlowManager(
            memory_integration=real_memory_integration,
            session_factory=session_factory,
        )

        player_id = uuid.uuid4()

        # Create conversation with progression
        conversation, _ = await conversation_repo_manager.create_complete_conversation(
            player_id=player_id,
            npc_id=npc_id,
            initial_message="Greetings, seeker of knowledge.",
            topic="introduction",
        )

        # Test memory integration at different relationship levels
        relationship_levels = [0.2, 0.5, 0.8]  # Stranger -> Friend -> Confidant

        for relationship_level in relationship_levels:
            conversation.relationship_level = relationship_level

            # Clear stage cache to force re-evaluation
            flow_manager._conversation_stages.clear()

            enhanced_response, integration_data = (
                await flow_manager.enhance_response_with_memory_patterns(
                    conversation=conversation,
                    personality=npc_personality,
                    base_response="I have much knowledge to share.",
                    player_message="Tell me about the ancient history of this place.",
                    npc_id=npc_id,
                )
            )

            # Higher relationship should allow deeper memory disclosure
            if relationship_level >= 0.5:
                assert integration_data.get("memory_enhanced", False)
                assert "disclosure_level" in integration_data

    async def test_memory_integration_error_recovery(
        self,
        session_factory: DatabaseSessionFactory,
        conversation_with_semantic_memories: tuple[
            ConversationContext, list[SemanticMemoryEntry]
        ],
    ):
        """Test memory integration error recovery and fallback mechanisms."""
        conversation, _ = conversation_with_semantic_memories

        # Create memory integration with failing LLM client
        failing_llm = AsyncMock(spec=OllamaClient)
        failing_llm.generate_response.side_effect = Exception("LLM service unavailable")

        memory_integration = MemoryIntegrationInterface(
            session_factory=session_factory,
            llm_client=failing_llm,
            enable_memory_enhancement=True,
        )

        # Create NPC personality
        npc_personality = NPCPersonality(
            npc_id=uuid.UUID(conversation.npc_id),
            traits={"helpful": 0.8},
            knowledge_areas=["history"],
            speech_patterns={},
            background_story="Village historian.",
            default_mood="neutral",
            relationships={},
        )

        # Test graceful error handling
        memory_context = await memory_integration.extract_memory_context(
            conversation=conversation,
            player_message="Tell me about the village history.",
            npc_personality=npc_personality,
        )

        # Should return minimal context on LLM failure
        assert memory_context.current_topic is None
        assert memory_context.emotional_tone == "neutral"
        assert len(memory_context.conversation_history) >= 0

    async def test_memory_integration_performance_with_large_dataset(
        self,
        db_session: AsyncSession,
        session_factory: DatabaseSessionFactory,
        semantic_memory_repo: SemanticMemoryRepository,
        mock_ollama_client: OllamaClient,
    ):
        """Test memory integration performance with larger memory datasets."""
        import time

        conversation_id = uuid.uuid4()
        npc_id = uuid.uuid4()
        player_id = uuid.uuid4()

        # Create large set of semantic memories
        memory_count = 100
        memories = []

        for i in range(memory_count):
            embedding = [0.1 + (i * 0.001)] * 384  # Varied embeddings
            memory = SemanticMemoryEntry(
                conversation_id=conversation_id,
                npc_id=npc_id,
                player_id=player_id,
                memory_text=f"Historical event {i}: Important village milestone occurred.",
                embedding=embedding,
                importance_score=0.5 + (i % 10) * 0.05,
                emotional_weight=0.3 + (i % 5) * 0.1,
                created_at=datetime.utcnow() - timedelta(days=i),
            )
            memories.append(await semantic_memory_repo.create_memory_entry(memory))

        # Create memory integration
        memory_integration = MemoryIntegrationInterface(
            session_factory=session_factory,
            llm_client=mock_ollama_client,
            similarity_threshold=0.6,
            max_memories_per_query=10,
        )

        # Test retrieval performance
        memory_context = MemoryContext(
            current_topic="village_events",
            emotional_tone="interested",
            npc_knowledge_areas=["history"],
        )

        start_time = time.perf_counter()

        memory_result = await memory_integration.retrieve_relevant_memories(
            memory_context=memory_context,
            npc_id=npc_id,
            query_embedding=[0.1] * 384,
        )

        end_time = time.perf_counter()
        duration = end_time - start_time

        # Performance assertions
        assert duration < 2.0  # Should complete within 2 seconds even with 100 memories
        assert len(memory_result.relevant_memories) <= 10  # Respects max limit
        assert not memory_result.fallback_triggered

        # Test that results are properly ranked by similarity
        similarities = [similarity for _, similarity in memory_result.relevant_memories]
        assert similarities == sorted(
            similarities, reverse=True
        )  # Should be in descending order


@pytest.mark.asyncio
class TestMemoryIntegrationEdgeCases:
    """Test edge cases and boundary conditions for memory integration."""

    async def test_empty_memory_database_handling(
        self,
        session_factory: DatabaseSessionFactory,
        mock_ollama_client: OllamaClient,
    ):
        """Test memory integration when no memories exist in database."""
        memory_integration = MemoryIntegrationInterface(
            session_factory=session_factory,
            llm_client=mock_ollama_client,
        )

        # Test with empty database
        memory_context = MemoryContext(current_topic="nonexistent_topic")
        npc_id = uuid.uuid4()

        memory_result = await memory_integration.retrieve_relevant_memories(
            memory_context=memory_context,
            npc_id=npc_id,
        )

        # Should handle gracefully
        assert len(memory_result.relevant_memories) == 0
        assert memory_result.context_score == 0.0
        assert memory_result.disclosure_recommendation == MemoryDisclosureLevel.NONE

    async def test_memory_integration_with_disabled_enhancement(
        self,
        session_factory: DatabaseSessionFactory,
        mock_ollama_client: OllamaClient,
    ):
        """Test memory integration when enhancement is disabled."""
        memory_integration = MemoryIntegrationInterface(
            session_factory=session_factory,
            llm_client=mock_ollama_client,
            enable_memory_enhancement=False,  # Disabled
        )

        memory_context = MemoryContext(current_topic="any_topic")
        npc_id = uuid.uuid4()

        memory_result = await memory_integration.retrieve_relevant_memories(
            memory_context=memory_context,
            npc_id=npc_id,
        )

        # Should return neutral result
        assert len(memory_result.relevant_memories) == 0
        assert memory_result.flow_analysis == ConversationFlowState.NATURAL
        assert memory_result.disclosure_recommendation == MemoryDisclosureLevel.NONE

    async def test_memory_retrieval_with_very_low_similarity_threshold(
        self,
        session_factory: DatabaseSessionFactory,
        mock_ollama_client: OllamaClient,
        conversation_with_semantic_memories: tuple[
            ConversationContext, list[SemanticMemoryEntry]
        ],
    ):
        """Test memory retrieval with very restrictive similarity threshold."""
        conversation, _ = conversation_with_semantic_memories

        # Create memory integration with very high similarity threshold
        memory_integration = MemoryIntegrationInterface(
            session_factory=session_factory,
            llm_client=mock_ollama_client,
            similarity_threshold=0.99,  # Very restrictive
        )

        memory_context = MemoryContext(current_topic="village_history")
        npc_id = uuid.UUID(conversation.npc_id)

        memory_result = await memory_integration.retrieve_relevant_memories(
            memory_context=memory_context,
            npc_id=npc_id,
            query_embedding=[0.1] * 384,
        )

        # With very high threshold, likely no matches
        assert len(memory_result.relevant_memories) == 0 or all(
            similarity >= 0.99 for _, similarity in memory_result.relevant_memories
        )
