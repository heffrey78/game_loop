llm:
  provider: "ollama"
  base_url: "http://localhost:11434"
  timeout: 60.0
  default_model: "qwen2.5:3b"
  embedding_model: "nomic-embed-text"

ollama:
  completion_params:
    temperature: 0.7
    top_p: 0.9
    top_k: 40
    max_tokens: 1024
  system_prompt: "You are an AI assistant for a text adventure game."

prompts:
  # Relative path from the config file to the prompt templates
  template_dir: "../../src/game_loop/llm/prompts"
  default_template: "default.txt"
